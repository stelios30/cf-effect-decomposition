version: "3.8"
services:
    ollama:
        container_name: ollama
        image: ollama/ollama
        env_file:
            - .env
        volumes:
            - ${OLLAMA_MODELS_DIR}:/root/.ollama
        ports:
            - 11434:11434
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]
    ollama-ui:
        container_name: ollama-ui
        image: ghcr.io/open-webui/open-webui:main
        restart: always
        env_file:
            - .env
        volumes:
            - ${OLLAMA_UI_DIR}:/app/backend/data
        extra_hosts:
            - "host.docker.internal:host-gateway"
        environment:
            - OLLAMA_API_BASE_URL=http://ollama:11434/api
        depends_on:
            - ollama
        ports:
            - 3000:8080
